{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import nltk\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to reset index when we split the dataframes\n",
    "def drop_index(df):\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the article dataframe and contents scraped by Newspaper\n",
    "df = pd.read_csv('web_scrape/contents.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean html column for those pesky \\n values\n",
    "df['html'] = df['html'].replace('\\n', ' ', regex=True).replace('Advertisement ', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regex to remove any photo text that is at the beginning of the article\n",
    "# Unfortunately, cannot grab all of them so some will eventually get in...\n",
    "# Will try to make Photo a stopword\n",
    "for i in range(len(df['html'])):\n",
    "    r = re.findall(r'(?<=\\( Shutterstock \\))(.*)', df['html'][i])\n",
    "    b = re.findall(r'(?<=\\( Getty Images \\))(.*)', df['html'][i])\n",
    "    if r:\n",
    "        df['html'][i] = r[0]\n",
    "    elif b:\n",
    "        df['html'][i] = b[0]\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Uncomment line below to see the sources in the notebook\n",
    "#df['sources'].unique()\n",
    "\n",
    "# Separating articles with no sources attached \n",
    "no_source = df[df['source'].isna()]\n",
    "no_source = drop_index(no_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating our sources into indiviudal dataframes \n",
    "wired = drop_index(df[df['source'] == 'wired'])\n",
    "the_verge = drop_index(df[df['source'] == 'the_verge'])\n",
    "bbc_news = drop_index(df[df['source'] == 'bbc-news'])\n",
    "cnn = drop_index(df[df['source'] == 'cnn'])\n",
    "techcrunch = drop_index(df[df['source'] == 'techcrunch'])\n",
    "mashable = drop_index(df[df['source'] == 'mashable'])\n",
    "engadget = drop_index(df[df['source'] == 'engadget'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rachehuang\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3343: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "# For those that have no sources, we are going to use regex to grab them from the URL\n",
    "for i in range(len(no_source['url'])):\n",
    "    r = re.findall(r'(.*)(?<=.com)', no_source['url'][i])\n",
    "    b = re.findall(r'(.*)(?<=.com)', no_source['url'][i]) \n",
    "    source = re.findall(r'(?<=\\.)(.*)(?<=\\.)', r[0])\n",
    "    source = source[0].replace(r'.', '')\n",
    "    if source == '':\n",
    "        source = re.findall(r'(?<=\\/\\/)(.*)(?<=\\.)', b[0])\n",
    "        source = source[0].replace(r'.', '')\n",
    "        no_source['source'][i] = source\n",
    "    else:\n",
    "        no_source['source'][i] = source\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['lifehacker', 'nytimes', 'gizmodo'], dtype=object)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uncomment this line to see the additional sources that we missed\n",
    "no_source.source.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we will put those into their own new dataframes. So far, we have 10 sources\n",
    "lifehacker = drop_index(no_source[no_source['source'] == 'lifehacker'])\n",
    "nytimes = drop_index(no_source[no_source['source'] == 'nytimes'])\n",
    "gizmodo = drop_index(no_source[no_source['source'] == 'gizmodo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'wired', 'the-verge', 'bbc-news', 'cnn', 'techcrunch',\n",
       "       'mashable', 'engadget'], dtype=object)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking to make sure there are no new sources when we run the API again\n",
    "df.source.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['theres', 'youre', 'covid', 'coronavirus', 'rules', 'risk', 'precautions', 'perfect', 'think', 'bubble', 'right', 'cases']\""
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lifehacker.key_words[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
